{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# __Case Study on Bitcoin's Price Journey (2014-2022)__\n",
        "### Team :\n",
        "    Venkata Sriram Amballa - 21BCS008\n",
        "    Devesh Kumar   - 21BCS032\n",
        "    Hrutik Ratan      - 21BCS022\n"
      ],
      "metadata": {
        "id": "GKGF7A7j3ctP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNIT-2**"
      ],
      "metadata": {
        "id": "npCmjPdK4ts7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "import math\n",
        "from scipy import stats\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/BTC-USD.csv\")\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dekxp_Y-_8qW",
        "outputId": "3cabce37-4b97-43f7-b959-fed6a2f053be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date        Open        High         Low       Close   Adj Close  \\\n",
            "0  2014-09-17  465.864014  468.174011  452.421997  457.334015  457.334015   \n",
            "1  2014-09-18  456.859985  456.859985  413.104004  424.440002  424.440002   \n",
            "2  2014-09-19  424.102997  427.834991  384.532013  394.795990  394.795990   \n",
            "3  2014-09-20  394.673004  423.295990  389.882996  408.903992  408.903992   \n",
            "4  2014-09-21  408.084991  412.425995  393.181000  398.821014  398.821014   \n",
            "5  2014-09-22  399.100006  406.915985  397.130005  402.152008  402.152008   \n",
            "6  2014-09-23  402.092010  441.557007  396.196991  435.790985  435.790985   \n",
            "7  2014-09-24  435.751007  436.112000  421.131989  423.204987  423.204987   \n",
            "8  2014-09-25  423.156006  423.519989  409.467987  411.574005  411.574005   \n",
            "9  2014-09-26  411.428986  414.937988  400.009003  404.424988  404.424988   \n",
            "\n",
            "     Volume  \n",
            "0  21056800  \n",
            "1  34483200  \n",
            "2  37919700  \n",
            "3  36863600  \n",
            "4  26580100  \n",
            "5  24127600  \n",
            "6  45099500  \n",
            "7  30627700  \n",
            "8  26814400  \n",
            "9  21460800  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One Sample Z-Test**\n"
      ],
      "metadata": {
        "id": "K4inKdw5Dl3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "data = df['Adj Close']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Hypothesis:\n",
        "# H0: μ (population mean) = 457.334015 (Choose the value based on your requirement)\n",
        "# H1: μ ≠ 457.334015\n",
        "\n",
        "\n",
        "sample_size = 50\n",
        "\n",
        "sample = np.random.choice(data, size=sample_size)\n",
        "\n",
        "sample_mean = np.mean(sample)\n",
        "\n",
        "population_mean = 457.334015\n",
        "\n",
        "population_std = np.std(data)\n",
        "\n",
        "z = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "z_tab = 1.64\n",
        "\n",
        "print(\"H0: μ =\", population_mean)\n",
        "print(\"H1: μ ≠\", population_mean)\n",
        "print(\"Sample Size (n):\", sample_size)\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"Population Mean:\", population_mean)\n",
        "print(\"Population Standard Deviation:\", population_std)\n",
        "print(\"Z-Score:\", z)\n",
        "print(\"Z-tabulated value : \",z_tab)\n",
        "\n",
        "\n",
        "if z > z_tab:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.norm.interval(0.95, loc=sample_mean, scale=(population_std / np.sqrt(sample_size)))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUfK5l78wgSR",
        "outputId": "dda88ab1-20a6-4dae-8c33-1689adabc665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H0: μ = 457.334015\n",
            "H1: μ ≠ 457.334015\n",
            "Sample Size (n): 50\n",
            "Sample Mean: 14870.262558920002\n",
            "Population Mean: 457.334015\n",
            "Population Standard Deviation: 16013.28238298123\n",
            "Z-Score: 6.364391301182821\n",
            "Z-tabulated value :  1.64\n",
            "Result: Reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (10431.688699927, 19308.836417913004)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Two Sample Z-Test**"
      ],
      "metadata": {
        "id": "DLit__aeSHzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "sample1 = df['Open']\n",
        "sample2 = df['Close']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "sample_size1 = 100\n",
        "sample_size2 = 100\n",
        "\n",
        "sample1 = np.random.choice(sample1, size=sample_size1)\n",
        "sample2 = np.random.choice(sample2, size=sample_size2)\n",
        "\n",
        "sample_mean1 = np.mean(sample1)\n",
        "sample_mean2 = np.mean(sample2)\n",
        "\n",
        "sample_std1 = np.std(sample1, ddof=1)\n",
        "sample_std2 = np.std(sample2, ddof=1)\n",
        "\n",
        "z = (sample_mean1 - sample_mean2) / np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2))\n",
        "\n",
        "print(\"Sample Size (n1):\", sample_size1)\n",
        "print(\"Sample Size (n2):\", sample_size2)\n",
        "print(\"Sample Mean (x̄1):\", sample_mean1)\n",
        "print(\"Sample Mean (x̄2):\", sample_mean2)\n",
        "print(\"Sample Standard Deviation (s1):\", sample_std1)\n",
        "print(\"Sample Standard Deviation (s2):\", sample_std2)\n",
        "print(\"Z-Score:\", z)\n",
        "\n",
        "z_critical = stats.norm.ppf(1 - alpha / 2)\n",
        "print(\"Critical Value:\", z_critical)\n",
        "\n",
        "if np.abs(z) > z_critical:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.norm.interval(0.95, loc=(sample_mean1 - sample_mean2), scale=np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2)))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yed20eJPkZI",
        "outputId": "2cf11cbe-ce7b-4c3d-9125-ea90a7cfcde0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Size (n1): 100\n",
            "Sample Size (n2): 100\n",
            "Sample Mean (x̄1): 11654.6714952\n",
            "Sample Mean (x̄2): 15805.033307040001\n",
            "Sample Standard Deviation (s1): 15221.580298135976\n",
            "Sample Standard Deviation (s2): 17313.39260567873\n",
            "Z-Score: -1.800340801038845\n",
            "Critical Value: 1.959963984540054\n",
            "Result: Fail to reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (-8668.706154934902, 367.9825312548992)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One Sample t-test**"
      ],
      "metadata": {
        "id": "1SGY8_UYULBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "data = df['Close']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "population_mean = 457.334015\n",
        "\n",
        "sample_size = 20\n",
        "\n",
        "sample = np.random.choice(data, size=sample_size)\n",
        "\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "\n",
        "t_stat = (sample_mean - population_mean) / (sample_std / np.sqrt(sample_size))\n",
        "\n",
        "df = sample_size - 1\n",
        "\n",
        "critical_t_value = stats.t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "print(\"H0: μ =\", population_mean)\n",
        "print(\"H1: μ ≠\", population_mean)\n",
        "print(\"Sample Size (n):\", sample_size)\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"Sample Standard Deviation:\", sample_std)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"Critical t-Value:\", critical_t_value)\n",
        "\n",
        "if np.abs(t_stat) > critical_t_value:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.t.interval(0.95, df, loc=sample_mean, scale=sample_std / np.sqrt(sample_size))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdDwgDlsU5-_",
        "outputId": "205cb3da-d1d7-4f82-9bb1-938374b95319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H0: μ = 457.334015\n",
            "H1: μ ≠ 457.334015\n",
            "Sample Size (n): 20\n",
            "Sample Mean: 15629.279712649999\n",
            "Sample Standard Deviation: 17615.646055767447\n",
            "T-Statistic: 3.851746546618822\n",
            "Degrees of Freedom: 19\n",
            "Critical t-Value: 2.093024054408263\n",
            "Result: Reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (7384.903580156779, 23873.65584514322)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Two Sample t-test**"
      ],
      "metadata": {
        "id": "sgiagNmPWUuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "sample1 = df['Open']\n",
        "sample2 = df['Close']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Hypothesis:\n",
        "# H0: μ1 (population mean of 'Open') = μ2 (population mean of 'Close')\n",
        "# H1: μ1 ≠ μ2\n",
        "\n",
        "sample_size1 = 18\n",
        "sample_size2 = 18\n",
        "sample1 = np.random.choice(sample1, size=sample_size1)\n",
        "sample2 = np.random.choice(sample2, size=sample_size2)\n",
        "\n",
        "sample_mean1 = np.mean(sample1)\n",
        "sample_mean2 = np.mean(sample2)\n",
        "\n",
        "sample_std1 = np.std(sample1, ddof=1)\n",
        "sample_std2 = np.std(sample2, ddof=1)\n",
        "\n",
        "t_stat = (sample_mean1 - sample_mean2) / np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2))\n",
        "\n",
        "df = sample_size1 + sample_size2 - 2\n",
        "\n",
        "# Calculate critical t-value for two-tailed test\n",
        "t_critical = stats.t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "print(\"H0: μ1 = μ2\")\n",
        "print(\"H1: μ1 ≠ μ2\")\n",
        "print(\"Sample Size (n1):\", sample_size1)\n",
        "print(\"Sample Size (n2):\", sample_size2)\n",
        "print(\"Sample Mean (x̄1):\", sample_mean1)\n",
        "print(\"Sample Mean (x̄2):\", sample_mean2)\n",
        "print(\"Sample Standard Deviation (s1):\", sample_std1)\n",
        "print(\"Sample Standard Deviation (s2):\", sample_std2)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"Critical t-value:\", t_critical)\n",
        "\n",
        "if np.abs(t_stat) > t_critical:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.t.interval(0.95, df, loc=(sample_mean1 - sample_mean2), scale=np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2)))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjpc_fmJWaCm",
        "outputId": "10111ca6-1460-49bd-82d2-2e1ef15ff64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H0: μ1 = μ2\n",
            "H1: μ1 ≠ μ2\n",
            "Sample Size (n1): 18\n",
            "Sample Size (n2): 18\n",
            "Sample Mean (x̄1): 15561.265645444442\n",
            "Sample Mean (x̄2): 5539.557156777778\n",
            "Sample Standard Deviation (s1): 14731.64670497574\n",
            "Sample Standard Deviation (s2): 7264.554510549099\n",
            "T-Statistic: 2.588576091673226\n",
            "Degrees of Freedom: 34\n",
            "Critical t-value: 2.032244509317718\n",
            "P-Value: 0.01407925012074207\n",
            "Result: Reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (2153.8454903219326, 17889.571487011395)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Independent Two sample T-test**"
      ],
      "metadata": {
        "id": "mkpb_q5ze5lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "sample1 = df['High']\n",
        "sample2 = df['Low']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Hypothesis:\n",
        "# H0: μ1 (population mean of 'High') = μ2 (population mean of 'Low')\n",
        "# H1: μ1 ≠ μ2\n",
        "\n",
        "sample_size1 = 18\n",
        "sample_size2 = 18\n",
        "\n",
        "sample1 = np.random.choice(sample1, size=sample_size1)\n",
        "sample2 = np.random.choice(sample2, size=sample_size2)\n",
        "\n",
        "sample_mean1 = np.mean(sample1)\n",
        "sample_mean2 = np.mean(sample2)\n",
        "\n",
        "sample_std1 = np.std(sample1, ddof=1)\n",
        "sample_std2 = np.std(sample2, ddof=1)\n",
        "\n",
        "t_stat = (sample_mean1 - sample_mean2) / np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2))\n",
        "\n",
        "df = sample_size1 + sample_size2 - 2\n",
        "\n",
        "t_critical = stats.t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "print(\"H0: μ1 = μ2\")\n",
        "print(\"H1: μ1 ≠ μ2\")\n",
        "print(\"Sample Size (n1):\", sample_size1)\n",
        "print(\"Sample Size (n2):\", sample_size2)\n",
        "print(\"Sample Mean (x̄1):\", sample_mean1)\n",
        "print(\"Sample Mean (x̄2):\", sample_mean2)\n",
        "print(\"Sample Standard Deviation (s1):\", sample_std1)\n",
        "print(\"Sample Standard Deviation (s2):\", sample_std2)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"Critical t-value:\", t_critical)\n",
        "\n",
        "if np.abs(t_stat) > t_critical:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.t.interval(0.95, df, loc=(sample_mean1 - sample_mean2), scale=np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2)))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "id": "I0EY3ll-e9i3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d53015c-b4fa-40e5-eaaa-7b2b401665e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H0: μ1 = μ2\n",
            "H1: μ1 ≠ μ2\n",
            "Sample Size (n1): 18\n",
            "Sample Size (n2): 18\n",
            "Sample Mean (x̄1): 12043.016532000001\n",
            "Sample Mean (x̄2): 13297.170887555556\n",
            "Sample Standard Deviation (s1): 14720.168828628797\n",
            "Sample Standard Deviation (s2): 14260.194747868469\n",
            "T-Statistic: -0.2596233294537216\n",
            "Degrees of Freedom: 34\n",
            "Critical t-value: 2.032244509317718\n",
            "Result: Fail to reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (-11071.254799793547, 8562.946088682438)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dependent Two sample T-test(paired)**\n"
      ],
      "metadata": {
        "id": "sk1Ux1qaoQGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "sample1 = df['Adj Close']\n",
        "sample2 = df['Close']\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Hypothesis:\n",
        "# H0: μ1 (population mean of 'Adj Close') = μ2 (population mean of 'Close')\n",
        "# H1: μ1 ≠ μ2\n",
        "\n",
        "sample_size1 = 15\n",
        "sample_size2 = 15\n",
        "\n",
        "sample1 = np.random.choice(sample1, size=sample_size1)\n",
        "sample2 = np.random.choice(sample2, size=sample_size2)\n",
        "\n",
        "sample_mean1 = np.mean(sample1)\n",
        "sample_mean2 = np.mean(sample2)\n",
        "\n",
        "sample_std1 = np.std(sample1, ddof=1)\n",
        "sample_std2 = np.std(sample2, ddof=1)\n",
        "\n",
        "t_stat = (sample_mean1 - sample_mean2) / np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2))\n",
        "\n",
        "df = sample_size1 + sample_size2 - 2\n",
        "\n",
        "\n",
        "t_critical = stats.t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "print(\"H0: μ1 = μ2\")\n",
        "print(\"H1: μ1 ≠ μ2\")\n",
        "print(\"Sample Size (n1):\", sample_size1)\n",
        "print(\"Sample Size (n2):\", sample_size2)\n",
        "print(\"Sample Mean (x̄1):\", sample_mean1)\n",
        "print(\"Sample Mean (x̄2):\", sample_mean2)\n",
        "print(\"Sample Standard Deviation (s1):\", sample_std1)\n",
        "print(\"Sample Standard Deviation (s2):\", sample_std2)\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"Critical t-value:\", t_critical)\n",
        "\n",
        "if t_stat > t_critical:\n",
        "    print(\"Result: Reject the null hypothesis (H0)\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis (H0)\")\n",
        "\n",
        "confidence_interval = stats.t.interval(0.95, df, loc=(sample_mean1 - sample_mean2), scale=np.sqrt((sample_std1**2 / sample_size1) + (sample_std2**2 / sample_size2)))\n",
        "print(\"95% Confidence Interval:\", confidence_interval)"
      ],
      "metadata": {
        "id": "a0bKhRf_nN8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1981a9b-0d90-4bdb-c012-03e8b749f955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H0: μ1 = μ2\n",
            "H1: μ1 ≠ μ2\n",
            "Sample Size (n1): 15\n",
            "Sample Size (n2): 15\n",
            "Sample Mean (x̄1): 5196.497689866666\n",
            "Sample Mean (x̄2): 10567.3243694\n",
            "Sample Standard Deviation (s1): 5895.957917303295\n",
            "Sample Standard Deviation (s2): 16007.404638872329\n",
            "T-Statistic: -1.2193848019377875\n",
            "Degrees of Freedom: 28\n",
            "Critical t-value: 2.048407141795244\n",
            "Result: Fail to reject the null hypothesis (H0)\n",
            "95% Confidence Interval: (-14393.113746107592, 3651.4603870409264)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Z-test for one-sample population proportion**"
      ],
      "metadata": {
        "id": "ehtoFGSD0jL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will aggregate the values and calculate the averages for that data as per years."
      ],
      "metadata": {
        "id": "ICkZn03bc7bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('BTC-USD.csv')\n",
        "\n",
        "\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "data['Year'] = data['Date'].dt.year\n",
        "\n",
        "\n",
        "yearly_data = data.groupby('Year').agg({\n",
        "    'Open': 'mean',\n",
        "    'High': 'max',\n",
        "    'Low': 'min',\n",
        "    'Close': 'mean',\n",
        "    'Adj Close': 'mean',\n",
        "    'Volume': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "print(yearly_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwVZboP4D2F2",
        "outputId": "092d7d65-f979-4640-9d5a-1237875d598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year          Open          High           Low         Close     Adj Close  \\\n",
            "0  2014    365.058217    468.174011    289.295990    363.693085    363.693085   \n",
            "1  2015    272.149011    495.562012    171.509995    272.453381    272.453381   \n",
            "2  2016    567.141429    979.396973    354.914001    568.492407    568.492407   \n",
            "3  2017   3970.644848  20089.000000    755.755981   4006.033629   4006.033629   \n",
            "4  2018   7601.018680  17712.400391   3191.303467   7572.298947   7572.298947   \n",
            "5  2019   7385.218456  13796.489258   3391.023682   7395.246282   7395.246282   \n",
            "6  2020  11056.787201  29244.876953   4106.980957  11116.378092  11116.378092   \n",
            "7  2021  47402.115663  68789.625000  28722.755859  47436.932021  47436.932021   \n",
            "8  2022  28278.690293  48086.835938  15599.046875  28197.754099  28197.754099   \n",
            "9  2023  25872.947656  31814.515625  16521.234375  25941.869356  25941.869356   \n",
            "\n",
            "           Volume  \n",
            "0      2526711120  \n",
            "1     12375531708  \n",
            "2     31448370984  \n",
            "3    869746420804  \n",
            "4   2213196541089  \n",
            "5   6106628278860  \n",
            "6  12086518388859  \n",
            "7  17211845901724  \n",
            "8  10954842244160  \n",
            "9   3986324518365  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Is the average closing price of Bitcoin significantly different from a specified population mean? Here we are considering for the year 2014 the population mean is coming as 363.693085\n",
        "\n",
        "Null Hypothesis (H0):\n",
        "The average closing price of Bitcoin is equal to a specified population mean. avg_mean = 363.693085\n",
        "\n",
        "\n",
        "Alternative Hypothesis (H1):\n",
        "The average closing price of Bitcoin is not equal to a specified population mean.\n",
        "\n"
      ],
      "metadata": {
        "id": "7KTsE1AibKaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "Year = 2014\n",
        "population_mean = 363.693085\n",
        "alpha = 0.05\n",
        "data = pd.read_csv('BTC-USD.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "\n",
        "yearly_close_prices = data[data['Year'] == Year]['Close']\n",
        "\n",
        "sample_mean = yearly_close_prices.mean()\n",
        "sample_std = yearly_close_prices.std()\n",
        "sample_size = len(yearly_close_prices)\n",
        "\n",
        "z_stat = (sample_mean - population_mean) / (sample_std / (sample_size ** 0.5))\n",
        "\n",
        "z_tab = stats.t.ppf(1 - alpha / 2, df=sample_size - 1)\n",
        "\n",
        "print(f\"Year: {Year}\")\n",
        "print(f\"Sample Mean: {sample_mean}\")\n",
        "print(f\"Population Mean: {population_mean}\")\n",
        "print(f\"Z-statistic: {z_stat}\")\n",
        "print(f\"Z-tabulated value: {z_tab}\")\n",
        "\n",
        "if z_stat > z_tab:\n",
        "    print(\"Reject the null hypothesis\")\n",
        "else:\n",
        "    print(\"Accept the null hypothesis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V6zhgKbEZYU",
        "outputId": "ad3d324a-ef79-459b-adf5-467119a33776"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year: 2014\n",
            "Sample Mean: 363.69308470754714\n",
            "Population Mean: 363.693085\n",
            "Z-statistic: -9.865054623582928e-08\n",
            "Z-tabulated value: 1.9828152737371543\n",
            "Accept the null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Z-test for two-sample population proportion**\n",
        "**Question:** Is there a significant difference in the proportion of days where the closing price of Bitcoin exceeds $5000 between the years 2019 and 2022?\n",
        "\n",
        "Null Hypothesis (H0):\n",
        "The proportion of days with closing prices above $5000 in 2019 is equal to the proportion in 2022.\n",
        "\n",
        "Alternative Hypothesis (H1):\n",
        "The proportion of days with closing prices above $5000 in 2019 is not equal to the proportion in 2022."
      ],
      "metadata": {
        "id": "Jht4w67a3SUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "df['Year'] = df['Date'].dt.year\n",
        "\n",
        "threshold = 5000\n",
        "sample_size = 10\n",
        "\n",
        "sample_2019 = df[df['Year'] == 2019]['Close'].sample(sample_size, random_state=42)\n",
        "sample_2022 = df[df['Year'] == 2022]['Close'].sample(sample_size, random_state=42)\n",
        "\n",
        "count_2019 = sum(sample_2019 > threshold)\n",
        "count_2022 = sum(sample_2022 > threshold)\n",
        "\n",
        "p1 = count_2019 / sample_size\n",
        "p2 = count_2022 / sample_size\n",
        "\n",
        "p_pooled = (count_2019 + count_2022) / (2 * sample_size)\n",
        "\n",
        "standard_error = np.sqrt(p_pooled * (1 - p_pooled) * (1 / sample_size + 1 / sample_size))\n",
        "\n",
        "z_stat = (p1 - p2) / standard_error\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "z_tab = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "print(\"\\nAlpha : \",alpha)\n",
        "\n",
        "print(f\"Z-Statistic: {z_stat}\")\n",
        "print(f\"Critical Z-Value: {z_tab}\")\n",
        "\n",
        "if abs(z_stat) > z_tab:\n",
        "    print(\"Reject the null hypothesis: There is enough evidence to suggest a difference in proportions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is not enough evidence to suggest a difference in proportions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3VLDKt7UyWL",
        "outputId": "63a7ab4b-7537-40bb-e7a4-1eca9b75939e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Alpha :  0.05\n",
            "Z-Statistic: -2.2360679774997902\n",
            "Critical Z-Value: 1.959963984540054\n",
            "Reject the null hypothesis: There is enough evidence to suggest a difference in proportions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 3**\n"
      ],
      "metadata": {
        "id": "ipfESOVHTuki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Runs Test**"
      ],
      "metadata": {
        "id": "-pWr0OrZPa0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aim to determine if a randomly selected sample of 100 Bitcoin price variations, spanning from 2014 to 2023, exhibits a random pattern or shows evidence of non-random behavior. This analysis will help assess whether fluctuations in Bitcoin prices, within this sample, are influenced by factors other than random market dynamics.\n",
        "\n",
        "Hypotheses:\n",
        "\n",
        "Null Hypothesis (H0): The selected sample of 100 Bitcoin price variations follows a random pattern, indicating that price fluctuations are driven by random market dynamics.\n",
        "\n",
        "Alternative Hypothesis (H1): The selected sample of 100 Bitcoin price variations does not follow a random pattern, suggesting the presence of non-random factors affecting Bitcoin price movements within this sample."
      ],
      "metadata": {
        "id": "Hh3DXUacZzGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "close_data = data['Close'].tolist()\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "sample_size = 100\n",
        "selected_data = np.random.choice(close_data, sample_size)\n",
        "\n",
        "def calculate_runs(data):\n",
        "    runs = []\n",
        "    current_run = 1\n",
        "\n",
        "    for i in range(1, len(data)):\n",
        "        if data[i] > data[i - 1]:\n",
        "            current_run += 1\n",
        "        elif data[i] < data[i - 1]:\n",
        "            current_run -= 1\n",
        "        runs.append(current_run)\n",
        "\n",
        "    return runs\n",
        "\n",
        "runs = calculate_runs(selected_data)\n",
        "\n",
        "N1 = runs.count(1)\n",
        "N2 = runs.count(-1)\n",
        "\n",
        "num_runs = len(set(runs))\n",
        "\n",
        "def runs_test(sign_cal, num_runs, alpha):\n",
        "    critical_value_lower = stats.binom.ppf(alpha / 2, num_runs, 0.5)\n",
        "    critical_value_upper = stats.binom.ppf(1 - alpha / 2, num_runs, 0.5)\n",
        "\n",
        "    print(f\"N1 (number of positive runs): {N1}\")\n",
        "    print(f\"N2 (number of negative runs): {N2}\")\n",
        "    print(f\"Total number of unique runs: {num_runs}\")\n",
        "    print(f\"Critical Value Range: {critical_value_lower}, {critical_value_upper}\")\n",
        "\n",
        "    if sign_cal <= critical_value_lower or sign_cal >= critical_value_upper:\n",
        "        print(\"Result: Reject the null hypothesis. The data is not random.\")\n",
        "    else:\n",
        "        print(\"Result: Fail to reject the null hypothesis. The data is random.\")\n",
        "\n",
        "alpha = 0.05\n",
        "print(\"Alpha : \",alpha)\n",
        "\n",
        "runs_test(abs(N1 - N2), num_runs, alpha)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9zGJb04uGWq",
        "outputId": "ae4f638c-9ace-4253-8e9f-fa36b0b48eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha :  0.05\n",
            "N1 (number of positive runs): 34\n",
            "N2 (number of negative runs): 13\n",
            "Total number of unique runs: 6\n",
            "Critical Value Range: 1.0, 5.0\n",
            "Result: Reject the null hypothesis. The data is not random.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **One Sample Signed Test**"
      ],
      "metadata": {
        "id": "KqwSc3goaEFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "year_data = data[data['Date'].str.startswith('2016')]\n",
        "\n",
        "np.random.seed(0)\n",
        "alpha = 0.05\n",
        "\n",
        "sample_size = 15\n",
        "\n",
        "if(sample_size >= 26):\n",
        "    selected_data = np.random.choice(year_data['Close'], sample_size)\n",
        "\n",
        "    hyp_median = 560\n",
        "\n",
        "    signs = np.sign(selected_data - hyp_median)\n",
        "\n",
        "    num_positive = np.sum(signs == 1)\n",
        "    num_negative = np.sum(signs == -1)\n",
        "\n",
        "    z_cal = (num_positive - num_negative) / np.sqrt(num_positive + num_negative)\n",
        "\n",
        "\n",
        "\n",
        "    z_tab = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    if abs(z_cal) > z_tab:\n",
        "        result = \"Reject the null hypothesis\"\n",
        "    else:\n",
        "        result = \"Fail to reject the null hypothesis\"\n",
        "\n",
        "    problem_statement = f\"We want to assess whether a random sample of 15 Bitcoin price variations for the year 2016 shows a significant difference from a hypothesized median of {hyp_median}.\"\n",
        "    h0 = f\"Null Hypothesis (H0): The median of the sample is {hyp_median}.\"\n",
        "    h1 = f\"Alternative Hypothesis (H1): The median of the sample is not {hyp_median}.\"\n",
        "\n",
        "    print(\"Sign Table:\")\n",
        "    for i, value in enumerate(selected_data):\n",
        "        print(f\"Sample Value {i+1}: {value:.2f}, Sign: {signs[i]}\")\n",
        "\n",
        "    print(\"\\nNumber of Positive Signs:\", num_positive)\n",
        "    print(\"Number of Negative Signs:\", num_negative)\n",
        "    print(\"\\nAlpha : \",alpha)\n",
        "    print(\"\\nZ-calculated : \",z_cal)\n",
        "    print(\"Z-tab (Critical Z-score):\", z_tab)\n",
        "    print(\"\\nResult of the Signed Test:\", result)\n",
        "else:\n",
        "    selected_data = np.random.choice(year_data['Close'], sample_size)\n",
        "\n",
        "    hyp_median = 560\n",
        "\n",
        "    signs = np.sign(selected_data - hyp_median)\n",
        "\n",
        "    num_positive = np.sum(signs == 1)\n",
        "    num_negative = np.sum(signs == -1)\n",
        "\n",
        "    print(\"\\nNo.of negative values : \",num_negative)\n",
        "    print(\"No.of positive values : \",num_positive)\n",
        "\n",
        "    test_value = min(num_positive,num_negative)\n",
        "    critical_value = 3\n",
        "\n",
        "    print(\"Alpha value : \",alpha)\n",
        "    print(\"Test value: \",test_value)\n",
        "    print(\"Critical value: \",critical_value)\n",
        "    if(test_value <= critical_value):\n",
        "        print(\"Reject null Hypothesis!!\")\n",
        "    else:\n",
        "        print(\"Accept null Hypothesis!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9-E0GoMvIOC",
        "outputId": "853cb473-413d-42b1-e584-8c8e45da9e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter sample size : 50\n",
            "Sign Table:\n",
            "Sample Value 1: 666.65, Sign: 1.0\n",
            "Sample Value 2: 416.32, Sign: -1.0\n",
            "Sample Value 3: 444.69, Sign: -1.0\n",
            "Sample Value 4: 647.66, Sign: 1.0\n",
            "Sample Value 5: 751.62, Sign: 1.0\n",
            "Sample Value 6: 626.32, Sign: 1.0\n",
            "Sample Value 7: 658.08, Sign: 1.0\n",
            "Sample Value 8: 896.18, Sign: 1.0\n",
            "Sample Value 9: 447.99, Sign: -1.0\n",
            "Sample Value 10: 655.05, Sign: 1.0\n",
            "Sample Value 11: 610.20, Sign: 1.0\n",
            "Sample Value 12: 577.50, Sign: 1.0\n",
            "Sample Value 13: 630.52, Sign: 1.0\n",
            "Sample Value 14: 424.23, Sign: -1.0\n",
            "Sample Value 15: 421.69, Sign: -1.0\n",
            "Sample Value 16: 416.52, Sign: -1.0\n",
            "Sample Value 17: 715.53, Sign: 1.0\n",
            "Sample Value 18: 664.55, Sign: 1.0\n",
            "Sample Value 19: 376.03, Sign: -1.0\n",
            "Sample Value 20: 424.23, Sign: -1.0\n",
            "Sample Value 21: 623.98, Sign: 1.0\n",
            "Sample Value 22: 416.52, Sign: -1.0\n",
            "Sample Value 23: 771.16, Sign: 1.0\n",
            "Sample Value 24: 685.56, Sign: 1.0\n",
            "Sample Value 25: 392.15, Sign: -1.0\n",
            "Sample Value 26: 735.60, Sign: 1.0\n",
            "Sample Value 27: 414.07, Sign: -1.0\n",
            "Sample Value 28: 596.30, Sign: 1.0\n",
            "Sample Value 29: 461.43, Sign: -1.0\n",
            "Sample Value 30: 575.47, Sign: 1.0\n",
            "Sample Value 31: 660.77, Sign: 1.0\n",
            "Sample Value 32: 756.77, Sign: 1.0\n",
            "Sample Value 33: 773.87, Sign: 1.0\n",
            "Sample Value 34: 419.41, Sign: -1.0\n",
            "Sample Value 35: 629.37, Sign: 1.0\n",
            "Sample Value 36: 575.47, Sign: 1.0\n",
            "Sample Value 37: 636.19, Sign: 1.0\n",
            "Sample Value 38: 473.46, Sign: -1.0\n",
            "Sample Value 39: 473.46, Sign: -1.0\n",
            "Sample Value 40: 638.65, Sign: 1.0\n",
            "Sample Value 41: 596.30, Sign: 1.0\n",
            "Sample Value 42: 683.66, Sign: 1.0\n",
            "Sample Value 43: 458.54, Sign: -1.0\n",
            "Sample Value 44: 374.45, Sign: -1.0\n",
            "Sample Value 45: 373.06, Sign: -1.0\n",
            "Sample Value 46: 665.01, Sign: 1.0\n",
            "Sample Value 47: 572.30, Sign: 1.0\n",
            "Sample Value 48: 531.39, Sign: -1.0\n",
            "Sample Value 49: 672.78, Sign: 1.0\n",
            "Sample Value 50: 703.70, Sign: 1.0\n",
            "\n",
            "Number of Positive Signs: 31\n",
            "Number of Negative Signs: 19\n",
            "\n",
            "Alpha :  0.05\n",
            "\n",
            "Z-calculated :  1.697056274847714\n",
            "Z-tab (Critical Z-score): 1.959963984540054\n",
            "\n",
            "Result of the Signed Test: Fail to reject the null hypothesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paired Sample Signed Test**"
      ],
      "metadata": {
        "id": "1-lD32goeFXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import binom\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "sample_size = 15\n",
        "random_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "random_sample['Difference'] = random_sample['Open'] - random_sample['Close']\n",
        "\n",
        "positive_signs = (random_sample['Difference'] > 0).sum()\n",
        "negative_signs = (random_sample['Difference'] < 0).sum()\n",
        "\n",
        "n = min(positive_signs, negative_signs)\n",
        "k = positive_signs + negative_signs\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = binom.ppf(1 - alpha / 2, k, 0.5)\n",
        "\n",
        "print(\"Paired Sample Sign Test (Random Sample of Size 15):\")\n",
        "print(\"H0: The median difference between Open and Close prices is zero.\")\n",
        "print(\"H1: The median difference between Open and Close prices is not zero.\")\n",
        "print(f\"Sign of differences in the random sample of size {sample_size}:\")\n",
        "for index, row in random_sample.iterrows():\n",
        "    sign = \"Positive\" if row['Difference'] > 0 else \"Negative\"\n",
        "    print(f\"{row['Date']}: {sign}\")\n",
        "\n",
        "print(f\"Number of positive signs: {positive_signs}\")\n",
        "print(f\"Number of negative signs: {negative_signs}\")\n",
        "print(f\"Size of the random sample: {k}\")\n",
        "print(f\"Critical Value: {critical_value}\")\n",
        "\n",
        "test_value = min(positive_signs,negative_signs)\n",
        "\n",
        "print(\"The test value we got here is \", test_value)\n",
        "\n",
        "if test_value < critical_value:\n",
        "    print(\"Result: Reject the null hypothesis. There is a significant difference.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. There is no significant difference.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjByZ01PsvRA",
        "outputId": "3f0b72a2-64cd-495d-f578-6c5ab817af9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paired Sample Sign Test (Random Sample of Size 15):\n",
            "H0: The median difference between Open and Close prices is zero.\n",
            "H1: The median difference between Open and Close prices is not zero.\n",
            "Sign of differences in the random sample of size 15:\n",
            "2015-12-10: Positive\n",
            "2020-06-15: Negative\n",
            "2015-07-13: Positive\n",
            "2023-02-10: Positive\n",
            "2019-01-24: Negative\n",
            "2020-06-07: Negative\n",
            "2021-11-29: Negative\n",
            "2014-12-19: Negative\n",
            "2019-07-02: Negative\n",
            "2019-08-11: Negative\n",
            "2020-06-23: Positive\n",
            "2022-02-01: Negative\n",
            "2014-10-17: Negative\n",
            "2021-02-06: Negative\n",
            "2023-04-29: Positive\n",
            "Number of positive signs: 5\n",
            "Number of negative signs: 10\n",
            "Size of the random sample: 15\n",
            "Critical Value: 11.0\n",
            "The test value we got here is  5\n",
            "Result: Reject the null hypothesis. There is a significant difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Wilcoxon Rank Sum Test**"
      ],
      "metadata": {
        "id": "BiGD1RMUzNer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For historical Bitcoin price data containing 'Open' and 'Close' prices. You want to investigate whether there is a significant difference between the 'Open' and 'Close' prices of Bitcoin. To achieve this, you will perform two statistical tests: the Wilcoxon rank-sum test and the z-test. These tests will help you determine if there is a significant difference between the 'Open' and 'Close' prices, both in terms of rank and statistical significance.\n",
        "\n",
        "Hypothesis Statement:\n",
        "\n",
        "Null Hypothesis (H0): There is no significant difference between the 'Open' and 'Close' prices of Bitcoin. In other words, the distribution of 'Open' prices is the same as that of 'Close' prices.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference between the 'Open' and 'Close' prices of Bitcoin. In other words, the distribution of 'Open' prices is different from that of 'Close' prices.\n",
        "\n",
        "The Wilcoxon rank-sum test will help us assess the difference in ranks between the 'Open' and 'Close' prices, while the z-test will evaluate the statistical significance of the observed difference.\n",
        "\n",
        "The code will test these hypotheses and provide the results based on the statistical tests and significance levels."
      ],
      "metadata": {
        "id": "c6mvVXKN2E02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ranksums\n",
        "from scipy.stats import norm\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "high_sample = data['High'].sample(16, random_state=42)\n",
        "close_sample = data['Close'].sample(20, random_state=42)\n",
        "\n",
        "statistic, p_value = ranksums(high_sample, close_sample)\n",
        "\n",
        "print(\"Hypothesis:\")\n",
        "print(\"H0: There is no significant difference between the High and Close samples.\")\n",
        "print(\"H1: There is a significant difference between the High and Close samples.\")\n",
        "\n",
        "high_ranks = high_sample.rank().sum()\n",
        "close_ranks = close_sample.rank().sum()\n",
        "\n",
        "print(\"\\nSum of Ranks:\\n\")\n",
        "print(f\"High Sample: {high_ranks}\")\n",
        "print(f\"Close Sample: {close_ranks}\")\n",
        "\n",
        "n1 = len(high_sample)\n",
        "n2 = len(close_sample)\n",
        "\n",
        "print(\"\\nLength of High sample : \",n1)\n",
        "print(\"Length of Low sample : \",n2)\n",
        "\n",
        "mean_rank = (n1 * (n1 + n2 + 1)) / 2\n",
        "std_dev = ((n1 * n2 * (n1 + n2 + 1)) / 12) ** 0.5\n",
        "z_value = (high_ranks - mean_rank) / std_dev\n",
        "\n",
        "print(\"\\nTest Statistic (z):\", z_value)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_z_value = norm.ppf(1 - alpha/2)\n",
        "\n",
        "print(\"\\nCritical Z-Value:\", critical_z_value)\n",
        "\n",
        "print(\"\\nHypothesis Testing:\")\n",
        "if abs(z_value) > critical_z_value:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the High and Close samples.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the High and Close samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw6vKf6V2H2W",
        "outputId": "5e9ecf4a-7205-4208-dc3a-9a478a79a18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypothesis:\n",
            "H0: There is no significant difference between the High and Close samples.\n",
            "H1: There is a significant difference between the High and Close samples.\n",
            "\n",
            "Sum of Ranks:\n",
            "\n",
            "High Sample: 136.0\n",
            "Close Sample: 210.0\n",
            "\n",
            "Length of High sample :  16\n",
            "Length of Low sample :  20\n",
            "\n",
            "Test Statistic (z): -5.093716319736107\n",
            "\n",
            "Critical Z-Value: 1.959963984540054\n",
            "\n",
            "Hypothesis Testing:\n",
            "Reject the null hypothesis. There is a significant difference between the High and Close samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Wilcoxon Signed-Rank Test**"
      ],
      "metadata": {
        "id": "14Bnl9s92eyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For historical Bitcoin price data containing 'Open' and 'Close' prices. Our objective is to investigate whether there is a significant difference between the 'Open' and 'Close' prices of Bitcoin. To accomplish this, we will perform two statistical tests: the Wilcoxon signed-rank test and the z-test. These tests will help determine if there is a statistically significant difference between the 'Open' and 'Close' prices.\n",
        "\n",
        "Hypothesis Statement:\n",
        "\n",
        "Null Hypothesis (H0): There is no significant difference between the 'Open' and 'Close' prices of Bitcoin. In other words, the distribution of 'Open' prices is the same as that of 'Close' prices.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference between the 'Open' and 'Close' prices of Bitcoin. In other words, the distribution of 'Open' prices is different from that of 'Close' prices.\n",
        "\n",
        "The Wilcoxon signed-rank test will assess the difference between paired 'Open' and 'Close' prices, while the z-test will evaluate the statistical significance of the observed difference.\n",
        "\n",
        "The code will test these hypotheses and provide the results based on the statistical tests and significance levels. It will also plot a scatter plot of 'Open' vs. 'Close' prices for visual inspection."
      ],
      "metadata": {
        "id": "jnafsDc13Df9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "n1 = 17\n",
        "n2 = 17\n",
        "\n",
        "open_prices = df['Open']\n",
        "close_prices = df['Close']\n",
        "\n",
        "random_sample1 = open_prices.sample(n=n1, random_state=1)\n",
        "random_sample2 = close_prices.sample(n=n2, random_state=1)\n",
        "\n",
        "differences = random_sample1 - random_sample2\n",
        "\n",
        "absolute_values = np.abs(differences)\n",
        "ranked_values = pd.Series(absolute_values).rank()\n",
        "\n",
        "signed_ranks = differences / absolute_values\n",
        "\n",
        "Ws_plus = sum(ranked_values[signed_ranks > 0])\n",
        "Ws_minus = sum(ranked_values[signed_ranks < 0])\n",
        "Ws_min = min(Ws_plus, Ws_minus)\n",
        "\n",
        "print(\"Differences:\", differences)\n",
        "print(\"Signed Ranks:\", signed_ranks)\n",
        "print(\"Ws+ (sum of positive ranks):\", Ws_plus)\n",
        "print(\"Ws- (sum of negative ranks):\", Ws_minus)\n",
        "print(\"Ws_min (minimum of sums):\", Ws_min)\n",
        "\n",
        "statistic, p_value = wilcoxon(random_sample1, random_sample2)\n",
        "print(\"\\nWilcoxon Signed-Rank Test Result:\")\n",
        "print(\"Statistic:\", statistic)\n",
        "\n",
        "alpha = 0.05\n",
        "print(f\"\\nAlpha: {alpha}\")\n",
        "critical_value = 35\n",
        "print(f\"Critical Value at 0.05 from the table: {critical_value}\")\n",
        "\n",
        "if statistic > critical_value:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the two samples.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1eDaPn3p1Is",
        "outputId": "81023617-63b5-4b5b-af96-bec66ecb1fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences: 1604      15.457763\n",
            "959      -36.309937\n",
            "3080     248.574219\n",
            "2084    -703.663086\n",
            "1827      49.547851\n",
            "1768     178.423828\n",
            "584       -4.421021\n",
            "1305    -111.570312\n",
            "2352    -870.246093\n",
            "2437   -4029.070312\n",
            "535       10.210999\n",
            "2796    -815.623047\n",
            "932      -56.869995\n",
            "797      -11.703980\n",
            "1851     -20.890625\n",
            "1970     -72.048828\n",
            "2184    -108.196289\n",
            "dtype: float64\n",
            "Signed Ranks: 1604    1.0\n",
            "959    -1.0\n",
            "3080    1.0\n",
            "2084   -1.0\n",
            "1827    1.0\n",
            "1768    1.0\n",
            "584    -1.0\n",
            "1305   -1.0\n",
            "2352   -1.0\n",
            "2437   -1.0\n",
            "535     1.0\n",
            "2796   -1.0\n",
            "932    -1.0\n",
            "797    -1.0\n",
            "1851   -1.0\n",
            "1970   -1.0\n",
            "2184   -1.0\n",
            "dtype: float64\n",
            "Ws+ (sum of positive ranks): 38.0\n",
            "Ws- (sum of negative ranks): 115.0\n",
            "Ws_min (minimum of sums): 38.0\n",
            "\n",
            "Wilcoxon Signed-Rank Test Result:\n",
            "Statistic: 38.0\n",
            "\n",
            "Alpha: 0.05\n",
            "Critical Value at 0.05 from the table: 35\n",
            "Reject the null hypothesis: There is a significant difference between the two samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 4**\n"
      ],
      "metadata": {
        "id": "h7CI35b8l1Jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-Square Goodness of Fit Test\n",
        "\n",
        "Question: Is there sufficient evidence to suggest that the distribution of daily percentage changes in Bitcoin prices, based on a random sample of size 50, differs from the expected distribution?"
      ],
      "metadata": {
        "id": "3yy3Wz3Jl_2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The distribution of daily percentage changes in Bitcoin prices, based on the random sample, follows the expected distribution.\n",
        "\n",
        "Alternative Hypothesis (H1): The distribution of daily percentage changes in Bitcoin prices, based on the random sample, does not follow the expected distribution."
      ],
      "metadata": {
        "id": "EQFStZabDLyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "from tabulate import tabulate\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "sample_size = 50\n",
        "random_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "random_sample['PercentageChanges'] = random_sample['Close'].pct_change() * 100\n",
        "\n",
        "expected_distribution = [30, 20, 20, 15, 15]\n",
        "\n",
        "bins = [float('-inf'), 0, 1, 2, 3, float('inf')]\n",
        "observed_counts, _ = np.histogram(random_sample['PercentageChanges'], bins=bins)\n",
        "\n",
        "total_observed = np.sum(observed_counts)\n",
        "expected_counts = np.array(expected_distribution) / 100 * total_observed\n",
        "\n",
        "print(\"Expected Distribution:\\n\")\n",
        "print(tabulate([expected_distribution], headers=[\"0%\", \"0-1%\", \"1-2%\", \"2-3%\", \"3%+\"], showindex=[\"Observed\"]))\n",
        "\n",
        "observed_table = [observed_counts.tolist(), expected_counts.tolist()]\n",
        "\n",
        "print(\"\\nObserved and Expected Values Table:\\n\")\n",
        "print(tabulate(observed_table, headers=[\"0%\", \"0-1%\", \"1-2%\", \"2-3%\", \"3%+\"], showindex=[\"Observed\", \"Expected\"]))\n",
        "\n",
        "degrees_of_freedom = len(bins) - 1\n",
        "\n",
        "print(\"\\nDegrees of Freedom: \", degrees_of_freedom)\n",
        "\n",
        "chi_square_statistic = np.sum((observed_counts - expected_counts)**2 / expected_counts)\n",
        "\n",
        "print(\"\\nChi-square statistic =\", chi_square_statistic)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = 11.071  # for degrees of freedom 4 and at alpha 0.05\n",
        "print(\"\\nCritical Value: \",critical_value)\n",
        "\n",
        "if chi_square_statistic > critical_value:\n",
        "    print(\"Reject H0. The distribution of daily percentage changes in the random sample deviates from the expected distribution.\")\n",
        "else:\n",
        "    print(\"Accept H0. There is no significant evidence of a deviation in the distribution of daily percentage changes in the random sample.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEiRU17Hi7mR",
        "outputId": "3653cddf-4c64-43f0-b009-abd4f54568ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Distribution:\n",
            "\n",
            "            0%    0-1%    1-2%    2-3%    3%+\n",
            "--------  ----  ------  ------  ------  -----\n",
            "Observed    30      20      20      15     15\n",
            "\n",
            "Observed and Expected Values Table:\n",
            "\n",
            "            0%    0-1%    1-2%    2-3%    3%+\n",
            "--------  ----  ------  ------  ------  -----\n",
            "Observed  23       1       0      1     24\n",
            "Expected  14.7     9.8     9.8    7.35   7.35\n",
            "\n",
            "Degrees of Freedom:  5\n",
            "\n",
            "Chi-square statistic = 65.59183673469387\n",
            "\n",
            "Critical Value:  11.071\n",
            "Reject H0. The distribution of daily percentage changes in the random sample deviates from the expected distribution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-square Test for Independence\n",
        "\n",
        "Question:Is there a significant association between closing prices (categorized as 'close < 15000' and 'close > 15000') and trading volumes (categorized as 'vol < 1000M' and 'vol > 1000M') in the population?"
      ],
      "metadata": {
        "id": "k906obZaxfTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant association between closing prices and trading volumes in the population.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant association between closing prices and trading volumes in the population."
      ],
      "metadata": {
        "id": "64LU8XLd9lyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2, chi2_contingency\n",
        "from tabulate import tabulate\n",
        "\n",
        "def count_values_in_ranges(data, column, ranges):\n",
        "    counts = np.zeros(len(ranges) - 1, dtype=int)\n",
        "    for i in range(len(ranges) - 1):\n",
        "        counts[i] = ((data[column] >= ranges[i]) & (data[column] < ranges[i + 1])).sum()\n",
        "    return counts\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "close_ranges = [0, 5000, 10000, 15000, 20000, 30000, float('inf')]\n",
        "volume_ranges = [0, 100_000_000, 500_000_000, 1_000_000_000, 5_000_000_000, float('inf')]\n",
        "\n",
        "sample_size = 50\n",
        "random_sample = df.sample(n=sample_size, random_state=12)\n",
        "\n",
        "close_counts = count_values_in_ranges(random_sample, 'Close', close_ranges)\n",
        "volume_counts = count_values_in_ranges(random_sample, 'Volume', volume_ranges)\n",
        "\n",
        "max_length = max(len(close_counts), len(volume_counts))\n",
        "\n",
        "close_counts = np.pad(close_counts, (0, max_length - len(close_counts)))\n",
        "volume_counts = np.pad(volume_counts, (0, max_length - len(volume_counts)))\n",
        "\n",
        "matrix_data = np.column_stack((close_counts, volume_counts))\n",
        "sum_of_columns = np.sum(matrix_data, axis=0, keepdims=True)\n",
        "matrix_data = np.vstack((matrix_data, sum_of_columns))\n",
        "\n",
        "sum_of_rows = np.sum(matrix_data, axis=1, keepdims=True)\n",
        "matrix_data = np.column_stack((matrix_data, sum_of_rows))\n",
        "\n",
        "ranges = ['0-5000', '5000-10000', '10000-15000', '15000-20000', '20000-30000', '30000+']\n",
        "columns = ['Close', 'Volume', 'Total']\n",
        "\n",
        "data = []\n",
        "for i in range(len(ranges)):\n",
        "    data.append([ranges[i]] + matrix_data[i, :].tolist())\n",
        "\n",
        "data.append(['Total'] + matrix_data[-1, :].tolist())\n",
        "\n",
        "print(\"Observed Values Table:\")\n",
        "print(tabulate(data, headers=columns))\n",
        "\n",
        "expected_matrix = np.zeros((len(ranges), len(columns) - 1))\n",
        "\n",
        "for i in range(len(ranges)):\n",
        "    for j in range(len(columns) - 1):\n",
        "        expected_matrix[i, j] = matrix_data[i, -1] * matrix_data[-1, j] / matrix_data[-1, -1]\n",
        "\n",
        "print(\"\\nExpected Values Matrix:\")\n",
        "print(tabulate(expected_matrix, headers=columns[:-1], showindex=ranges))\n",
        "\n",
        "chi_square_statistic, _, _, _ = chi2_contingency(matrix_data[:-1, :-1])\n",
        "\n",
        "df = (matrix_data.shape[0] - 2) * (matrix_data.shape[1] - 2)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = chi2.ppf(1 - alpha, df)\n",
        "\n",
        "print(\"\\nChi-square statistic =\", chi_square_statistic)\n",
        "print(\"Degrees of freedom =\", df)\n",
        "print(\"Critical value =\", critical_value)\n",
        "\n",
        "if chi_square_statistic >= critical_value:\n",
        "    print(\"Reject H0. There is a significant association between closing prices and trading volumes.\")\n",
        "else:\n",
        "    print(\"Accept H0. There is no significant association between closing prices and trading volumes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzCL5wROFoA4",
        "outputId": "24249862-10e7-46e1-b945-48aba4a3db58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed Values Table:\n",
            "               Close    Volume    Total\n",
            "-----------  -------  --------  -------\n",
            "0-5000            17        10       27\n",
            "5000-10000        14         2       16\n",
            "10000-15000        3         1        4\n",
            "15000-20000        6         7       13\n",
            "20000-30000        4        30       34\n",
            "30000+             6         0        6\n",
            "Total             50        50      100\n",
            "\n",
            "Expected Values Matrix:\n",
            "               Close    Volume\n",
            "-----------  -------  --------\n",
            "0-5000          13.5      13.5\n",
            "5000-10000       8         8\n",
            "10000-15000      2         2\n",
            "15000-20000      6.5       6.5\n",
            "20000-30000     17        17\n",
            "30000+           3         3\n",
            "\n",
            "Chi-square statistic = 37.77409083291437\n",
            "Degrees of freedom = 5\n",
            "Critical value = 11.070497693516351\n",
            "Reject H0. There is a significant association between closing prices and trading volumes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chi-square 2x2 contingency table test"
      ],
      "metadata": {
        "id": "kH49e0D5sfm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: There is a significant difference between Closing prices and volume\n",
        "\n",
        "Alternate Hypothesis: There is no significant difference between closing prices and volume"
      ],
      "metadata": {
        "id": "Ptzjg2I5kGGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "close_ranges = [0, 15000, float('inf')]\n",
        "volume_ranges = [0, 1_000_000_000, float('inf')]\n",
        "\n",
        "sample_size = 50\n",
        "random_sample = df.sample(n=sample_size, random_state=12)\n",
        "\n",
        "random_sample['Close_Binary'] = pd.cut(random_sample['Close'], bins=close_ranges, labels=[\"close < 15000\", \"close > 15000\"], include_lowest=True)\n",
        "random_sample['Volume_Binary'] = pd.cut(random_sample['Volume'], bins=volume_ranges, labels=['vol < 1000M', 'vol > 1000M'], include_lowest=True)\n",
        "\n",
        "contingency_table = pd.crosstab(random_sample['Close_Binary'], random_sample['Volume_Binary'], margins=True, margins_name=\"Total\")\n",
        "\n",
        "print(\"Observed Values Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "chi_square_statistic, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "df = (contingency_table.shape[0] - 2) * (contingency_table.shape[1] - 2)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = chi2.ppf(1 - alpha, df)\n",
        "\n",
        "print(\"\\nChi-square statistic =\", chi_square_statistic)\n",
        "print(\"Degrees of freedom =\", df)\n",
        "print(\"Critical value =\", critical_value)\n",
        "\n",
        "if chi_square_statistic >= critical_value:\n",
        "    print(\"Reject H0. There is a significant association between closing prices and trading volumes.\")\n",
        "else:\n",
        "    print(\"Accept H0. There is no significant association between closing prices and trading volumes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB_l-s5h1AoR",
        "outputId": "6cc5ed27-0cf3-4119-a508-12841eaa4a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed Values Table:\n",
            "Volume_Binary  vol < 1000M  vol > 1000M  Total\n",
            "Close_Binary                                  \n",
            "close < 15000           13           21     34\n",
            "close > 15000            0           16     16\n",
            "Total                   13           37     50\n",
            "\n",
            "Chi-square statistic = 8.267090620031798\n",
            "Degrees of freedom = 1\n",
            "Critical value = 3.841458820694124\n",
            "Reject H0. There is a significant association between closing prices and trading volumes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-square test for homogeneity\n",
        "Question: Is there a significant association between closing prices and trading volumes in a randomly selected sample of 50 data points from the cryptocurrency market, where the closing prices are categorized as 'close < 15000' and 'close > 15000', and the trading volumes are categorized as 'vol < 1000M' and 'vol > 1000M'?(M here suggests Million)"
      ],
      "metadata": {
        "id": "R15oi_HG027Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant association between closing prices and trading volumes in the cryptocurrency market.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant association between closing prices and trading volumes in the cryptocurrency market."
      ],
      "metadata": {
        "id": "BVNo4Pzi6ovc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2, chi2_contingency\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "close_ranges = [0, 15000, float('inf')]\n",
        "volume_ranges = [0, 1_000_000_000, float('inf')]\n",
        "\n",
        "random_sample = df.sample(n=50, random_state=12)\n",
        "\n",
        "random_sample['Close_Binary'] = pd.cut(random_sample['Close'], bins=close_ranges, labels=[\"close < 15000\", \"close > 15000\"], include_lowest=True)\n",
        "random_sample['Volume_Binary'] = pd.cut(random_sample['Volume'], bins=volume_ranges, labels=['vol < 1000M', 'vol > 1000M'], include_lowest=True)\n",
        "\n",
        "contingency_table = pd.crosstab(random_sample['Close_Binary'], random_sample['Volume_Binary'], margins=True, margins_name=\"Total\")\n",
        "\n",
        "print(\"Observed Values Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "chi_square_statistic, p_value, degrees_of_freedom, expected_frequencies = chi2_contingency(contingency_table.iloc[:-1, :-1])\n",
        "\n",
        "print(\"\\nChi-square statistic =\", chi_square_statistic)\n",
        "print(\"Degrees of freedom =\", degrees_of_freedom)\n",
        "\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected_frequencies)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = chi2.ppf(1 - alpha, degrees_of_freedom)\n",
        "print(\"Critical value : \", critical_value)\n",
        "\n",
        "if chi_square_statistic >= critical_value:\n",
        "    print(\"Reject H0. There is a significant association between closing prices and trading volumes.\")\n",
        "else:\n",
        "    print(\"Accept H0. There is no significant association between closing prices and trading volumes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke_vrYLx4Zru",
        "outputId": "507b3a3b-694a-4f62-f482-aa14d90738fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed Values Table:\n",
            "Volume_Binary  vol < 1000M  vol > 1000M  Total\n",
            "Close_Binary                                  \n",
            "close < 15000           13           21     34\n",
            "close > 15000            0           16     16\n",
            "Total                   13           37     50\n",
            "\n",
            "Chi-square statistic = 6.399237189678367\n",
            "Degrees of freedom = 1\n",
            "Expected frequencies:\n",
            "[[ 8.84 25.16]\n",
            " [ 4.16 11.84]]\n",
            "Critical value :  3.841458820694124\n",
            "Reject H0. There is a significant association between closing prices and trading volumes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yates correction test\n",
        "Question: Is there a significant association between closing prices (categorized as 'close < 15000' and 'close > 15000') and trading volumes (categorized as 'vol < 1000M' and 'vol > 1000M') in a random sample of 50 observations from the dataset?"
      ],
      "metadata": {
        "id": "-QfrjbnO7Wg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant association between closing prices and trading volumes in the population.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant association between closing prices and trading volumes in the population."
      ],
      "metadata": {
        "id": "geXFgHj88_bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "df = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "close_ranges = [0, 15000, float('inf')]\n",
        "volume_ranges = [0, 1_000_000_000, float('inf')]\n",
        "\n",
        "df['Close_Binary'] = pd.cut(df['Close'], bins=close_ranges, labels=[0, 1], include_lowest=True)\n",
        "df['Volume_Binary'] = pd.cut(df['Volume'], bins=volume_ranges, labels=[0, 1], include_lowest=True)\n",
        "\n",
        "random_sample = df.sample(n=50, random_state=42)\n",
        "\n",
        "contingency_table = pd.crosstab(random_sample['Close_Binary'], random_sample['Volume_Binary'], margins=True, margins_name=\"Total\")\n",
        "\n",
        "chi_square_statistic, _, _, expected_values = chi2_contingency(contingency_table, correction=True)\n",
        "\n",
        "df = (contingency_table.shape[0] - 2) * (contingency_table.shape[1] - 2)\n",
        "\n",
        "alpha = 0.05\n",
        "critical_value = chi2.ppf(1 - alpha, df)\n",
        "\n",
        "print(\"Observed Values Table:\")\n",
        "print(contingency_table)\n",
        "print(\"\\nChi-square statistic =\", chi_square_statistic)\n",
        "print(\"\\nDegrees of freedom =\", df)\n",
        "print(\"\\nExpected frequencies:\")\n",
        "print(expected_values)\n",
        "print(\"\\nCritical value : \",critical_value)\n",
        "\n",
        "\n",
        "if chi_square_statistic >= critical_value:\n",
        "    print(\"Reject H0. There is a significant association between closing prices and trading volumes.\")\n",
        "else:\n",
        "    print(\"Accept H0. There is no significant association between closing prices and trading volumes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X78FMs_p7cUa",
        "outputId": "a0fa765c-1d41-4b08-d9b1-ae0bdb3a2cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed Values Table:\n",
            "Volume_Binary   0   1  Total\n",
            "Close_Binary                \n",
            "0              16  15     31\n",
            "1               0  19     19\n",
            "Total          16  34     50\n",
            "\n",
            "Chi-square statistic = 14.421252371916507\n",
            "\n",
            "Degrees of freedom = 1\n",
            "\n",
            "Expected frequencies:\n",
            "[[ 9.92 21.08 31.  ]\n",
            " [ 6.08 12.92 19.  ]\n",
            " [16.   34.   50.  ]]\n",
            "\n",
            "Critical value :  3.841458820694124\n",
            "Reject H0. There is a significant association between closing prices and trading volumes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 5**"
      ],
      "metadata": {
        "id": "0VpkZrC2Grpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Size for a proportion\n"
      ],
      "metadata": {
        "id": "Qfj4muRcHhZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering the provided data on daily stock prices, the researcher is interested in studying the closing prices (Close column). Assuming a 95% confidence level and a margin of error of less than $5.00, what would be the required sample size to estimate the population mean of closing prices with a known population standard deviation?"
      ],
      "metadata": {
        "id": "i0-h_t8tNtCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "data_2014 = data[data['Date'].str.startswith('2014')]\n",
        "\n",
        "closing_prices_2014 = data_2014['Close']\n",
        "\n",
        "confidence_level = 0.95\n",
        "margin_of_error = 5.00\n",
        "\n",
        "expected_sd = closing_prices_2014.std()\n",
        "\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "sample_size = np.ceil((z_score**2 * expected_sd**2) / margin_of_error**2)\n",
        "\n",
        "print(f\"\\nExpected Standard Deviation (2014): {expected_sd}\")\n",
        "print(f\"Confidence Level: {confidence_level}\")\n",
        "print(f\"Margin of Error: {margin_of_error}\")\n",
        "print(f\"Z-Score: {z_score}\")\n",
        "print(f\"Required Sample Size: {int(sample_size)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5-p0uiEOgv4",
        "outputId": "8e3f2b90-f433-4ed7-9286-2f5fc9ba41df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expected Standard Deviation (2014): 30.521740867373502\n",
            "Confidence Level: 0.95\n",
            "Margin of Error: 5.0\n",
            "Z-Score: 1.959963984540054\n",
            "Required Sample Size: 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A researcher is interested in estimating the proportion of days in which the closing price of a stock increased over the provided dataset. Assuming a 95% confidence level and a margin of error of less than 5%, what would be the required sample size to estimate this proportion?"
      ],
      "metadata": {
        "id": "HoQOcGMCVhy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "closing_prices = data['Close']\n",
        "data['Price_Increased'] = closing_prices.diff() > 0\n",
        "sample_proportion = data['Price_Increased'].mean()\n",
        "\n",
        "confidence_level = 0.95\n",
        "margin_of_error = 0.05\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "sample_size_proportion = (z_score**2 * sample_proportion * (1 - sample_proportion)) / margin_of_error**2\n",
        "sample_size_proportion = np.ceil(sample_size_proportion)\n",
        "print(\"The sample proportion we are taking here is : \",sample_proportion)\n",
        "\n",
        "print(f\"The required sample size for estimating the proportion is: {int(sample_size_proportion)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2pNvZqRWOcV",
        "outputId": "29825eaa-8e85-46e2-9c83-513ca5147563"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sample proportion we are taking here is :  0.5306691449814126\n",
            "The required sample size for estimating the proportion is: 383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two sample proportions"
      ],
      "metadata": {
        "id": "Hl-ZUi4WWd0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Question: A researcher is investigating two different investment approaches for a stock. The researcher aims to detect a difference of 10 points or more in the average closing prices between the two approaches with a significance level (α) of 0.05 and a power (1−β) of 0.90. The population standard deviation (σ) for the closing prices is estimated to be 29 points. What would be the required sample size for each approach?\n",
        "\n"
      ],
      "metadata": {
        "id": "bGaZM62iYDP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "\n",
        "data_2014 = data[data['Date'].str.startswith('2014')]\n",
        "\n",
        "closing_prices_2014 = data_2014['Close']\n",
        "\n",
        "alpha = 0.05\n",
        "beta = 0.10\n",
        "power = 1 - beta\n",
        "sigma = closing_prices_2014.std()\n",
        "d = 10\n",
        "\n",
        "z_alpha = stats.norm.ppf(1 - alpha)\n",
        "z_beta = stats.norm.ppf(power)\n",
        "\n",
        "sample_size_per_group = (2 * (z_alpha + z_beta)**2 * sigma**2) / d**2\n",
        "sample_size_per_group = np.ceil(sample_size_per_group)\n",
        "total_sample_size = 2 * sample_size_per_group\n",
        "\n",
        "print(f\"Parameters:\")\n",
        "print(f\"   Significance level (alpha): {alpha}\")\n",
        "print(f\"   Power (1 - beta): {power}\")\n",
        "print(f\"   Population standard deviation (sigma): {sigma}\")\n",
        "print(f\"   Difference in means to detect (d): {d}\")\n",
        "\n",
        "print(f\"\\nThe required sample size per approach is: {int(sample_size_per_group)}\")\n",
        "print(f\"The total required sample size for both approaches is: {int(total_sample_size)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd46oBqkZboI",
        "outputId": "1bb1c23a-34ec-4ed8-e065-5aaa701985b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:\n",
            "   Significance level (alpha): 0.05\n",
            "   Power (1 - beta): 0.9\n",
            "   Population standard deviation (sigma): 30.521740867373502\n",
            "   Difference in means to detect (d): 10\n",
            "\n",
            "The required sample size per approach is: 160\n",
            "The total required sample size for both approaches is: 320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: A researcher is comparing the proportions of days with positive closing price changes between two different investment strategies using the provided dataset. The researcher aims to detect a difference of 0.05 or more in the proportions with a significance level (α) of 0.05 and a power (1−β) of 0.90. The estimated standard deviation (sd) for the proportions is 0.2. What would be the required sample size for each strategy?\n"
      ],
      "metadata": {
        "id": "sCOZgfosaFXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = pd.read_csv('/content/BTC-USD.csv')\n",
        "closing_prices = data['Close']\n",
        "data['Price_Increased'] = closing_prices.diff() > 0\n",
        "\n",
        "alpha = 0.05\n",
        "beta = 0.10\n",
        "power = 1 - beta\n",
        "sd = 0.2\n",
        "d = 0.05\n",
        "\n",
        "z_alpha = stats.norm.ppf(1 - alpha/2)\n",
        "z_beta = stats.norm.ppf(power)\n",
        "\n",
        "sample_size_1 = (4 * sd**2 * (z_alpha + z_beta)**2) / d**2\n",
        "sample_size_2 = sample_size_1\n",
        "total_sample_size = sample_size_1 + sample_size_2\n",
        "\n",
        "print(f\"Parameters:\")\n",
        "print(f\"   Significance level (alpha): {alpha}\")\n",
        "print(f\"   Power (1 - beta): {power}\")\n",
        "print(f\"   Standard deviation of proportions (sd): {sd}\")\n",
        "print(f\"   Difference in proportions to detect (d): {d}\")\n",
        "\n",
        "print(f\"\\nThe required sample size for each strategy is: {int(sample_size_1)}\")\n",
        "print(f\"The total required sample size for both strategies is: {int(total_sample_size)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkEJEzY_aY97",
        "outputId": "87d0eca6-30f7-4549-a7b1-1bc19abac5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:\n",
            "   Significance level (alpha): 0.05\n",
            "   Power (1 - beta): 0.9\n",
            "   Standard deviation of proportions (sd): 0.2\n",
            "   Difference in proportions to detect (d): 0.05\n",
            "\n",
            "The required sample size for each strategy is: 672\n",
            "The total required sample size for both strategies is: 1344\n"
          ]
        }
      ]
    }
  ]
}